#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«–é—œç¯€ç§»å‹•è»Œè·¡è¿½è¹¤ç³»çµ± - å½±ç‰‡åˆ†æç‰ˆ
å°ˆé–€ç”¨æ–¼åˆ†æå½±ç‰‡ä¸­äººç‰©é«–é—œç¯€æ°´å¹³ç§»å‹•æ¨¡å¼
é©ç”¨æ–¼æŠ•çƒå‹•ä½œåˆ†æ
"""

import cv2
import mediapipe as mp
import time
import math
import os
import sys
from collections import deque
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

class HipVideoAnalyzer:
    """é«–é—œç¯€è»Œè·¡è¿½è¹¤å™¨ï¼ˆåªè¨ˆç®—æ°´å¹³ç§»å‹•ï¼Œä¸”åœ¨å¹¾ä¹ä¸å‹•æ™‚æš«åœè¨˜éŒ„ï¼‰"""

    def __init__(self, max_history=300, stationary_px_threshold=5):
        self.max_history = max_history
        # é–¾å€¼ï¼šå¦‚æœæ°´å¹³ä½ç§»ï¼ˆåƒç´ ï¼‰ä½æ–¼æ­¤å€¼ï¼Œè¦–ç‚ºæœªç§»å‹•
        self.stationary_px_threshold = stationary_px_threshold

        # é«–é—œç¯€è»Œè·¡è¨˜éŒ„
        self.center_hip_trajectory = deque(maxlen=max_history)
        self.timestamps = deque(maxlen=max_history)
        self.speeds = deque(maxlen=max_history)
        self.speed_history = deque(maxlen=max_history)

        # ç§»å‹•çµ±è¨ˆï¼ˆåªç´¯è¨ˆæ°´å¹³è·é›¢ï¼‰
        self.total_displacement = 0.0   # ç´¯è¨ˆæ°´å¹³ä½ç§»ï¼ˆå…¬å°ºï¼‰
        self.max_speed = 0.0            # æ°´å¹³æœ€å¤§é€Ÿåº¦ï¼ˆm/sï¼‰

        # æ ¡æ­£åƒæ•¸ï¼šåƒç´  / å…¬å°º
        self.pixels_per_meter = 296  # åˆå§‹å€¼ï¼Œå¯ç”± calibrate_scale() èª¿æ•´

        # å½±ç‰‡ç›¸é—œåƒæ•¸
        self.video_path = None
        self.video_fps = 0
        self.video_frame_count = 0
        self.current_frame = 0
        self.playback_speed = 1.0
        self.video_width = 0
        self.video_height = 0
        self.cap = None

        # åˆå§‹åŒ– MediaPipe
        self.mp_holistic = mp.solutions.holistic
        self.holistic = self.mp_holistic.Holistic(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

        print("ğŸ¯ é«–é—œç¯€è»Œè·¡è¿½è¹¤å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ é è¨­æ¯”ä¾‹ï¼šæ¯å…¬å°º {self.pixels_per_meter} åƒç´ ")

    def load_video(self, video_path):
        """è¼‰å…¥å½±ç‰‡æª”æ¡ˆ"""
        try:
            # è™•ç†è·¯å¾‘
            video_path = os.path.abspath(video_path)
            print(f"ğŸ“‚ æ­£åœ¨å˜—è©¦é–‹å•Ÿå½±ç‰‡: {video_path}")
            print(f"ğŸ“‚ ç•¶å‰å·¥ä½œç›®éŒ„: {os.getcwd()}")
            
            if not os.path.exists(video_path):
                print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ '{video_path}'")
                print("è«‹ç¢ºèªï¼š")
                print("1. æª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
                print("2. æª”æ¡ˆåç¨±æ˜¯å¦æ­£ç¢ºï¼ˆåŒ…æ‹¬å‰¯æª”åï¼‰")
                print("3. æª”æ¡ˆæ˜¯å¦åœ¨æ­£ç¢ºçš„ç›®éŒ„ä¸­")
                return False

            # æª¢æŸ¥æª”æ¡ˆæ¬Šé™
            if not os.access(video_path, os.R_OK):
                print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–æª”æ¡ˆ '{video_path}'")
                print("è«‹ç¢ºèªæª”æ¡ˆæ¬Šé™æ˜¯å¦æ­£ç¢º")
                return False

            self.video_path = video_path
            self.cap = cv2.VideoCapture(video_path)
            
            if not self.cap.isOpened():
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿå½±ç‰‡")
                print("å¯èƒ½çš„åŸå› ï¼š")
                print("1. æª”æ¡ˆæ ¼å¼ä¸æ”¯æ´")
                print("2. æª”æ¡ˆæå£")
                print("3. æª”æ¡ˆè·¯å¾‘åŒ…å«ç‰¹æ®Šå­—å…ƒ")
                print("4. æª”æ¡ˆæ¬Šé™å•é¡Œ")
                return False
                
            # ç²å–å½±ç‰‡è³‡è¨Š
            self.video_fps = self.cap.get(cv2.CAP_PROP_FPS)
            self.video_frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.video_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            self.video_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            if self.video_fps <= 0 or self.video_frame_count <= 0:
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±ç‰‡è³‡è¨Š")
                print(f"FPS: {self.video_fps}")
                print(f"ç¸½å¹€æ•¸: {self.video_frame_count}")
                return False
            
            print(f"ğŸ“¹ å½±ç‰‡è³‡è¨Š:")
            print(f"è§£æåº¦: {self.video_width}x{self.video_height}")
            print(f"å¹€ç‡: {self.video_fps} FPS")
            print(f"ç¸½å¹€æ•¸: {self.video_frame_count}")
            print(f"æª”æ¡ˆå¤§å°: {os.path.getsize(video_path) / (1024*1024):.2f} MB")
            
            # æ¸¬è©¦è®€å–ç¬¬ä¸€å¹€
            ret, frame = self.cap.read()
            if not ret or frame is None:
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±ç‰‡å¹€")
                return False
                
            # é‡ç½®å½±ç‰‡ä½ç½®
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def calibrate_scale(self, known_distance_pixels, known_distance_meters):
        """æ ¡æ­£åƒç´ åˆ°å…¬å°ºçš„æ¯”ä¾‹"""
        if known_distance_meters <= 0:
            print("âŒ æ ¡æ­£å¤±æ•—ï¼šå…¬å°ºè·é›¢éœ€å¤§æ–¼ 0")
            return
        self.pixels_per_meter = known_distance_pixels / known_distance_meters
        print(f"âœ… æ ¡æ­£å®Œæˆï¼šæ¯å…¬å°º {self.pixels_per_meter:.1f} åƒç´ ")

    def extract_hip_landmarks(self, results):
        """æå–å·¦å³é«–é—œç¯€ä¸­å¿ƒçš„åº§æ¨™ï¼ˆåƒç´ ï¼‰"""
        if not results.pose_landmarks:
            return None

        landmarks = results.pose_landmarks.landmark
        lh = landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP]
        rh = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP]

        left_hip_px = (int(lh.x * self.video_width), int(lh.y * self.video_height))
        right_hip_px = (int(rh.x * self.video_width), int(rh.y * self.video_height))
        center_hip_px = (
            (left_hip_px[0] + right_hip_px[0]) // 2,
            (left_hip_px[1] + right_hip_px[1]) // 2
        )
        return center_hip_px

    def add_hip_position(self, center_px, timestamp):
        """
        æ·»åŠ é«–é—œç¯€ä½ç½®ï¼š
        - åƒ…åœ¨æ°´å¹³ä½ç§»è¶…éé–¾å€¼æ™‚ï¼Œæ‰ append ä¸”è¨ˆç®—é€Ÿåº¦ã€ç´¯åŠ è·é›¢ã€‚
        - å¦å‰‡è¦–ç‚ºã€Œéœæ­¢ã€ï¼Œæš«åœè¨˜éŒ„ã€‚
        """
        if not self.center_hip_trajectory:
            # ç¬¬ä¸€æ¬¡é€²å…¥ï¼Œç„¡é ˆæ¯”è¼ƒï¼Œç›´æ¥åŠ å…¥
            self.center_hip_trajectory.append(center_px)
            self.timestamps.append(timestamp)
            return

        prev_x, prev_y = self.center_hip_trajectory[-1]
        curr_x, curr_y = center_px

        dx_px = abs(curr_x - prev_x)
        # åªç”¨æ°´å¹³ä½ç§»åˆ¤æ–·æ˜¯å¦ç§»å‹•
        if dx_px < self.stationary_px_threshold:
            # æ°´å¹³ä½ç§»åœ¨é–¾å€¼ä¹‹å…§ï¼Œè¦–ç‚ºæœªç§»å‹•ï¼Œè·³é append
            return

        # æ°´å¹³ä½ç§»è¶…éé–¾å€¼ï¼Œæ‰è¨˜éŒ„æ–°é»
        self.center_hip_trajectory.append(center_px)
        self.timestamps.append(timestamp)
        # è¨ˆç®—æ°´å¹³é€Ÿåº¦èˆ‡ç´¯åŠ æ°´å¹³è·é›¢
        self._calculate_horizontal_movement(prev_x, curr_x)

    def _calculate_horizontal_movement(self, prev_x, curr_x):
        """è¨ˆç®—æ°´å¹³é€Ÿåº¦èˆ‡ç´¯åŠ æ°´å¹³è·é›¢ï¼Œä¸¦æ›´æ–°æœ€å¤§é€Ÿåº¦"""
        dx_px = abs(curr_x - prev_x)
        # åƒç´ è½‰å…¬å°º
        dx_m = dx_px / self.pixels_per_meter

        # å–æœ€å¾Œå…©å€‹ timestamp è¨ˆç®— dt
        t_now = self.timestamps[-1]
        t_prev = self.timestamps[-2]
        dt = t_now - t_prev
        if dt <= 0:
            return

        speed_ms = dx_m / dt
        self.speeds.append(speed_ms)
        self.speed_history.append(speed_ms)
        if speed_ms > self.max_speed:
            self.max_speed = speed_ms

        self.total_displacement += dx_m

    def get_movement_statistics(self):
        """å›å‚³æ°´å¹³ç§»å‹•çµ±è¨ˆè³‡æ–™ï¼ˆé€Ÿåº¦ã€è·é›¢ç­‰ï¼‰"""
        if not self.speeds:
            return None
        avg_speed = sum(self.speeds) / len(self.speeds)
        return {
            'current_speed': self.speeds[-1] if self.speeds else 0,
            'average_speed': avg_speed,
            'max_speed': self.max_speed,
            'total_horizontal_distance': self.total_displacement,
            'trajectory_points': len(self.center_hip_trajectory)
        }

    def draw_trajectory(self, frame):
        """ç¹ªè£½é«–é—œç¯€ä¸­å¿ƒçš„æ°´å¹³è»Œè·¡ï¼ˆä¿ç•™æ—¢æœ‰è»Œè·¡ï¼‰"""
        pts = list(self.center_hip_trajectory)
        if len(pts) < 2:
            return frame

        for i in range(1, len(pts)):
            prev_pt = pts[i - 1]
            curr_pt = pts[i]
            # é¡è‰²å¯ä¾æ“šç´¢å¼•æ¼¸è®Š
            ratio = i / len(pts)
            color = (int(255 * ratio), int(255 * (1 - ratio)), 128)
            cv2.line(frame, prev_pt, curr_pt, color, 2)

        # ç•«ç•¶å‰ä½ç½®
        if pts:
            cx, cy = pts[-1]
            cv2.circle(frame, (cx, cy), 8, (0, 255, 0), -1)
            cv2.circle(frame, (cx, cy), 12, (255, 255, 255), 2)
        return frame

    def draw_statistics(self, frame):
        """åœ¨å½±åƒä¸Šé¡¯ç¤ºæ°´å¹³ç§»å‹•çµ±è¨ˆè³‡è¨Š"""
        stats = self.get_movement_statistics()
        if not stats:
            cv2.putText(frame, "No movement data", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            return frame

        font = cv2.FONT_HERSHEY_SIMPLEX
        fs = 0.6
        th = 2
        lh = 25

        # èƒŒæ™¯æ¡†
        cv2.rectangle(frame, (10, 10), (400, 160), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (400, 160), (255, 255, 255), 2)

        y = 35
        cv2.putText(frame, "Horizontal Movement Stats", (15, y), font, 0.7, (0, 255, 255), 2)
        y += lh
        cv2.putText(frame, f"Curr Speed: {stats['current_speed']:.3f} m/s",
                    (15, y), font, fs, (255, 255, 255), th)
        y += lh
        cv2.putText(frame, f"Avg Speed: {stats['average_speed']:.3f} m/s",
                    (15, y), font, fs, (200, 200, 200), th)
        y += lh
        cv2.putText(frame, f"Max Speed: {stats['max_speed']:.3f} m/s",
                    (15, y), font, fs, (0, 255, 0), th)
        y += lh
        cv2.putText(frame, f"Total Hori Dist: {stats['total_horizontal_distance']:.3f} m",
                    (15, y), font, fs, (255, 255, 255), th)

        return frame

    def process_video_frame(self, frame):
        """è™•ç†å½±ç‰‡å¹€"""
        if frame is None:
            return None

        try:
            # è½‰æ›é¡è‰²ç©ºé–“
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.holistic.process(image)
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # ç¹ªè£½éª¨æ¶
            if results.pose_landmarks:
                self.mp_drawing.draw_landmarks(
                    image,
                    results.pose_landmarks,
                    self.mp_holistic.POSE_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    self.mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=2)
                )

                center_px = self.extract_hip_landmarks(results)
                if center_px:
                    # åªåœ¨æ°´å¹³ç§»å‹•è¶…éé–¾å€¼æ™‚æ‰è¨˜éŒ„
                    current_time = self.current_frame / self.video_fps
                    self.add_hip_position(center_px, current_time)

                # ç¹ªè£½è»Œè·¡èˆ‡çµ±è¨ˆ
                image = self.draw_trajectory(image)
                image = self.draw_statistics(image)

            # æ·»åŠ å½±ç‰‡è³‡è¨Š
            cv2.putText(image, f"Frame: {self.current_frame}/{self.video_frame_count}",
                        (10, self.video_height - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(image, f"Time: {self.current_frame/self.video_fps:.2f}s",
                        (10, self.video_height - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(image, f"Speed: {self.playback_speed}x",
                        (10, self.video_height - 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            return image

        except Exception as e:
            print(f"âŒ è™•ç†å½±ç‰‡å¹€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return frame

    def smooth_data(self, data, window_size=5):
        """ä½¿ç”¨ç§»å‹•å¹³å‡å¹³æ»‘æ•¸æ“š"""
        if len(data) < window_size:
            return data
        return np.convolve(data, np.ones(window_size)/window_size, mode='valid')

    def export_analysis_report(self):
        """åŒ¯å‡ºåˆ†æå ±å‘Š"""
        try:
            if not self.speed_history or not self.timestamps:
                print("âŒ æ²’æœ‰å¯åŒ¯å‡ºçš„æ•¸æ“š")
                return

            # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´
            min_length = min(len(self.timestamps), len(self.speed_history))
            if min_length == 0:
                print("âŒ æ²’æœ‰å¯åŒ¯å‡ºçš„æ•¸æ“š")
                return

            timestamps = list(self.timestamps)[:min_length]
            speed_history = list(self.speed_history)[:min_length]

            # æ ¹æ“šå½±ç‰‡FPSèª¿æ•´å¹³æ»‘çª—å£å¤§å°
            window_size = max(3, min(7, int(self.video_fps / 10)))  # é™ä½å¹³æ»‘ç¨‹åº¦
            smoothed_speed = self.smooth_data(speed_history, window_size)
            
            # èª¿æ•´æ™‚é–“æˆ³ä»¥åŒ¹é…å¹³æ»‘å¾Œçš„æ•¸æ“šé•·åº¦
            smoothed_timestamps = timestamps[window_size-1:]

            # å‰µå»ºè¼¸å‡ºç›®éŒ„
            output_dir = 'analysis_reports'
            try:
                if not os.path.exists(output_dir):
                    os.makedirs(output_dir)
            except Exception as e:
                print(f"âŒ ç„¡æ³•å‰µå»ºè¼¸å‡ºç›®éŒ„: {e}")
                return

            # ç”Ÿæˆæª”æ¡ˆåç¨±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            base_filename = f'hip_analysis_report_{timestamp}'

            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            try:
                max_speed = max(speed_history)
                avg_speed = sum(speed_history)/len(speed_history)
            except Exception as e:
                print(f"âŒ è¨ˆç®—çµ±è¨ˆæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return

            # é€Ÿåº¦-æ™‚é–“åœ–è¡¨
            try:
                plt.figure(figsize=(12, 6))
                # ç¹ªè£½åŸå§‹æ•¸æ“šï¼ˆåŠé€æ˜ï¼‰
                plt.plot(timestamps, speed_history, 'b-', alpha=0.3, label='åŸå§‹é€Ÿåº¦')
                # ç¹ªè£½å¹³æ»‘å¾Œçš„æ•¸æ“š
                plt.plot(smoothed_timestamps, smoothed_speed, 'r-', label='å¹³æ»‘å¾Œé€Ÿåº¦')
                plt.title(f'é«–é—œç¯€æ°´å¹³ç§»å‹•é€Ÿåº¦åˆ†æ\n'
                         f'æœ€å¤§é€Ÿåº¦: {max_speed:.2f} m/s | å¹³å‡é€Ÿåº¦: {avg_speed:.2f} m/s\n'
                         f'å½±ç‰‡è³‡è¨Š: {self.video_width}x{self.video_height} @ {self.video_fps}fps',
                         fontsize=12, pad=20)
                plt.xlabel('æ™‚é–“ (ç§’)', fontsize=10)
                plt.ylabel('é€Ÿåº¦ (m/s)', fontsize=10)
                plt.grid(True, linestyle='--', alpha=0.7)
                plt.legend(fontsize=10)
                
                # æ·»åŠ çµ±è¨ˆè³‡è¨Š
                plt.text(0.02, 0.98, 
                        f'æœ€å¤§é€Ÿåº¦: {max_speed:.2f} m/s\n'
                        f'å¹³å‡é€Ÿåº¦: {avg_speed:.2f} m/s\n'
                        f'ç¸½æ°´å¹³ç§»å‹•è·é›¢: {self.total_displacement:.2f} m\n'
                        f'å¹³æ»‘çª—å£å¤§å°: {window_size} å¹€',
                        transform=plt.gca().transAxes,
                        verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, f'{base_filename}_speed.png'), dpi=300, bbox_inches='tight')
                plt.close()
            except Exception as e:
                print(f"âŒ ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return

            # ç”Ÿæˆæ–‡å­—å ±å‘Š
            try:
                report_path = os.path.join(output_dir, f'{base_filename}_report.txt')
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write("é«–é—œç¯€æ°´å¹³ç§»å‹•åˆ†æå ±å‘Š\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"å½±ç‰‡è³‡è¨Š:\n")
                    f.write(f"è§£æåº¦: {self.video_width}x{self.video_height}\n")
                    f.write(f"å¹€ç‡: {self.video_fps} FPS\n")
                    f.write(f"ç¸½å¹€æ•¸: {self.video_frame_count}\n")
                    if self.video_path and os.path.exists(self.video_path):
                        f.write(f"æª”æ¡ˆå¤§å°: {os.path.getsize(self.video_path) / (1024*1024):.2f} MB\n")
                    f.write("\n")
                    
                    f.write("é‹å‹•æ•¸æ“š:\n")
                    f.write(f"æœ€å¤§é€Ÿåº¦: {max_speed:.2f} m/s\n")
                    f.write(f"å¹³å‡é€Ÿåº¦: {avg_speed:.2f} m/s\n")
                    f.write(f"ç¸½æ°´å¹³ç§»å‹•è·é›¢: {self.total_displacement:.2f} m\n")
                    f.write(f"å¹³æ»‘çª—å£å¤§å°: {window_size} å¹€\n")
                    
                    f.write("\næ™‚é–“é»åˆ†æ:\n")
                    for i, (t, s) in enumerate(zip(smoothed_timestamps, smoothed_speed)):
                        f.write(f"æ™‚é–“ {t:.2f}s: é€Ÿåº¦ {s:.2f} m/s\n")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆæ–‡å­—å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return

            print(f"âœ… åˆ†æå ±å‘Šå·²ä¿å­˜è‡³: {output_dir}")
            print(f"ğŸ“Š å·²ç”Ÿæˆåœ–è¡¨ï¼š")
            print(f"   - {base_filename}_speed.png")
            print(f"ğŸ“ å·²ç”Ÿæˆå ±å‘Šï¼š{base_filename}_report.txt")

        except Exception as e:
            print(f"âŒ åŒ¯å‡ºåˆ†æå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

def main():
    print("\n" + "=" * 50)
    print("ğŸš€ é«–é—œç¯€æ°´å¹³ç§»å‹•åˆ†æç³»çµ±")
    print("=" * 50)
    
    # é¡¯ç¤ºç³»çµ±è³‡è¨Š
    print("\nğŸ“‹ ç³»çµ±è³‡è¨Š:")
    print(f"ä½œæ¥­ç³»çµ±: {os.name}")
    print(f"å·¥ä½œç›®éŒ„: {os.getcwd()}")
    print(f"Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    
    try:
        print(f"\nğŸ“‹ å¥—ä»¶ç‰ˆæœ¬:")
        print(f"OpenCV ç‰ˆæœ¬: {cv2.__version__}")
        print(f"MediaPipe ç‰ˆæœ¬: {mp.__version__}")
        print(f"NumPy ç‰ˆæœ¬: {np.__version__}")
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–ç‰ˆæœ¬ä¿¡æ¯: {e}")

    # æª¢æŸ¥å¿…è¦çš„ç›®éŒ„
    print("\nğŸ“‚ ç›®éŒ„æª¢æŸ¥:")
    if not os.path.exists('analysis_reports'):
        try:
            os.makedirs('analysis_reports')
            print("âœ… å·²å‰µå»º analysis_reports ç›®éŒ„")
        except Exception as e:
            print(f"âŒ ç„¡æ³•å‰µå»º analysis_reports ç›®éŒ„: {e}")
    else:
        print("âœ… analysis_reports ç›®éŒ„å·²å­˜åœ¨")

    analyzer = HipVideoAnalyzer()
    
    # è™•ç†å½±ç‰‡è·¯å¾‘è¼¸å…¥
    print("\nğŸ“¹ è«‹è¼¸å…¥å½±ç‰‡è·¯å¾‘")
    print("æç¤ºï¼š")
    print("1. å¯ä»¥ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ˆä¾‹å¦‚ï¼švideos/test.mp4ï¼‰")
    print("2. æˆ–ä½¿ç”¨çµ•å°è·¯å¾‘ï¼ˆä¾‹å¦‚ï¼šC:/Users/YourName/Videos/test.mp4ï¼‰")
    print("3. æ”¯æ´çš„æ ¼å¼ï¼šMP4, AVI, MOV ç­‰")
    print("4. æŒ‰ Ctrl+C å¯ä»¥éš¨æ™‚é€€å‡ºç¨‹å¼")
    print("-" * 50)
    
    while True:
        try:
            video_path = input("\nè«‹è¼¸å…¥å½±ç‰‡è·¯å¾‘: ").strip()
            if not video_path:
                print("âŒ éŒ¯èª¤ï¼šè·¯å¾‘ä¸èƒ½ç‚ºç©º")
                continue
                
            # ç§»é™¤å¼•è™Ÿï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            video_path = video_path.strip('"\'')
            
            if analyzer.load_video(video_path):
                break
            else:
                print("\nè«‹é‡æ–°è¼¸å…¥å½±ç‰‡è·¯å¾‘ï¼Œæˆ–æŒ‰ Ctrl+C é€€å‡ºç¨‹å¼")
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼å·²çµ‚æ­¢")
            return
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("è«‹é‡æ–°è¼¸å…¥å½±ç‰‡è·¯å¾‘")

    print("\nğŸ¬ é–‹å§‹åˆ†æå½±ç‰‡...")
    print("ğŸ“ æ§åˆ¶èªªæ˜:")
    print("p: æš«åœ/æ¢å¾©")
    print("r: é‡ç½®")
    print("e: åŒ¯å‡ºåˆ†æå ±å‘Š")
    print("[: æ¸›æ…¢æ’­æ”¾é€Ÿåº¦")
    print("]: åŠ å¿«æ’­æ”¾é€Ÿåº¦")
    print("c: æ ¡æ­£è·é›¢æ¯”ä¾‹")
    print("ESC: é€€å‡º")
    print("-" * 50)

    try:
        print("\nğŸ¤– æ­£åœ¨åˆå§‹åŒ– MediaPipe Holistic...")
        print("âœ… MediaPipe Holistic åˆå§‹åŒ–æˆåŠŸ")
        
        paused = False
        analysis_complete = False

        while True:
            if not paused:
                ret, frame = analyzer.cap.read()
                if not ret:
                    print("\nâœ… å½±ç‰‡æ’­æ”¾å®Œæˆ")
                    analysis_complete = True
                    break

                processed_frame = analyzer.process_video_frame(frame)
                if processed_frame is not None:
                    cv2.imshow('Hip Horizontal Tracker', processed_frame)
                    analyzer.current_frame += 1

            wait_time = max(1, int(1000/analyzer.video_fps/analyzer.playback_speed))
            key = cv2.waitKey(wait_time) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('r'):  # Reset
                analyzer.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                analyzer.current_frame = 0
            elif key == ord('p'):  # Pause/Resume
                paused = not paused
                print("â¸ æš«åœ" if paused else "â–¶ï¸ æ¢å¾©")
            elif key == ord('e'):  # Export Report
                analyzer.export_analysis_report()
            elif key == ord('['):  # Slow down
                analyzer.playback_speed = max(0.25, analyzer.playback_speed - 0.25)
                print(f"æ’­æ”¾é€Ÿåº¦: {analyzer.playback_speed}x")
            elif key == ord(']'):  # Speed up
                analyzer.playback_speed = min(2.0, analyzer.playback_speed + 0.25)
                print(f"æ’­æ”¾é€Ÿåº¦: {analyzer.playback_speed}x")
            elif key == ord('c'):  # Calibrate
                print("\n=== è·é›¢æ ¡æ­£ ===")
                print("è«‹åœ¨çµ‚ç«¯è¼¸å…¥ï¼šå·²çŸ¥è·é›¢(å…¬å°º) èˆ‡ å°æ‡‰çš„åƒç´ é•·åº¦")
                vals = input("æ ¼å¼ â†’ [å…¬å°º] [åƒç´ ] ï¼š").strip().split()
                if len(vals) == 2:
                    try:
                        km = float(vals[0])
                        kp = float(vals[1])
                        analyzer.calibrate_scale(kp, km)
                    except:
                        print("âŒ è¼¸å…¥éŒ¯èª¤")
                else:
                    print("âŒ è¼¸å…¥æ•¸é‡ä¸ç¬¦")

        # å½±ç‰‡æ’­æ”¾å®Œæˆå¾Œï¼Œè©¢å•æ˜¯å¦è¦åŒ¯å‡ºå ±å‘Š
        if analysis_complete:
            print("\nğŸ“Š åˆ†æå®Œæˆï¼")
            export = input("æ˜¯å¦è¦åŒ¯å‡ºåˆ†æå ±å‘Šï¼Ÿ(y/n): ").lower()
            if export == 'y':
                analyzer.export_analysis_report()
                print("âœ… å ±å‘Šå·²åŒ¯å‡º")

    except Exception as e:
        print(f"\nâŒ ä¸»ç¨‹å¼å´©æ½°: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if analyzer.cap is not None:
            analyzer.cap.release()
        cv2.destroyAllWindows()
        print("\nğŸ§¹ è³‡æºå·²é‡‹æ”¾")
        print("ğŸ‘‹ ç¨‹å¼çµæŸ")

if __name__ == "__main__":
    main() 