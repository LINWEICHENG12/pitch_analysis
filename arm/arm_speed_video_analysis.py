import cv2
import mediapipe as mp
import time
import math
from collections import deque
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os
import sys

class ArmAxisTracker:
    def __init__(self, max_history=300, pixels_per_meter=346.8):
        self.max_history = max_history
        self.pixels_per_meter = pixels_per_meter
        self.positions = deque(maxlen=max_history)
        self.speeds = deque(maxlen=max_history)
        self.angles = deque(maxlen=max_history)
        self.time_history = deque(maxlen=max_history)
        self.speed_history = deque(maxlen=max_history)
        self.wrist_speed_history = deque(maxlen=max_history)  # æ–°å¢ï¼šæ‰‹æŒé€Ÿåº¦æ­·å²
        self.elbow_speed_history = deque(maxlen=max_history)  # æ–°å¢ï¼šæ‰‹è‚˜é€Ÿåº¦æ­·å²
        self.wrist_acceleration_history = deque(maxlen=max_history)  # æ–°å¢ï¼šæ‰‹æŒåŠ é€Ÿåº¦æ­·å²
        self.recording = False
        self.record_start_time = 0
        self.video_path = None
        self.video_fps = 0
        self.video_frame_count = 0
        self.current_frame = 0
        self.playback_speed = 1.0  # æ’­æ”¾é€Ÿåº¦å€ç‡
        self.video_width = 0
        self.video_height = 0
        self.cap = None
        
        # åˆå§‹åŒ– MediaPipe
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles

    def load_video(self, video_path):
        """è¼‰å…¥å½±ç‰‡"""
        try:
            # è™•ç†è·¯å¾‘
            video_path = os.path.abspath(video_path)
            print(f"ğŸ“‚ æ­£åœ¨å˜—è©¦é–‹å•Ÿå½±ç‰‡: {video_path}")
            print(f"ğŸ“‚ ç•¶å‰å·¥ä½œç›®éŒ„: {os.getcwd()}")
            
            if not os.path.exists(video_path):
                print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ '{video_path}'")
                print("è«‹ç¢ºèªï¼š")
                print("1. æª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
                print("2. æª”æ¡ˆåç¨±æ˜¯å¦æ­£ç¢ºï¼ˆåŒ…æ‹¬å‰¯æª”åï¼‰")
                print("3. æª”æ¡ˆæ˜¯å¦åœ¨æ­£ç¢ºçš„ç›®éŒ„ä¸­")
                return False

            # æª¢æŸ¥æª”æ¡ˆæ¬Šé™
            if not os.access(video_path, os.R_OK):
                print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–æª”æ¡ˆ '{video_path}'")
                print("è«‹ç¢ºèªæª”æ¡ˆæ¬Šé™æ˜¯å¦æ­£ç¢º")
                return False

            self.video_path = video_path
            self.cap = cv2.VideoCapture(video_path)
            
            if not self.cap.isOpened():
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿå½±ç‰‡")
                self.cap.release()  # ç¢ºä¿é‡‹æ”¾è³‡æº
                print("ğŸ”„ å·²é‡‹æ”¾éƒ¨åˆ†åˆå§‹åŒ–çš„è³‡æº")
                print("å¯èƒ½çš„åŸå› ï¼š")
                print("1. æª”æ¡ˆæ ¼å¼ä¸æ”¯æ´")
                print("2. æª”æ¡ˆæå£")
                print("3. æª”æ¡ˆè·¯å¾‘åŒ…å«ç‰¹æ®Šå­—å…ƒ")
                print("4. æª”æ¡ˆæ¬Šé™å•é¡Œ")
                return False
                
            # ç²å–å½±ç‰‡è³‡è¨Š
            self.video_fps = self.cap.get(cv2.CAP_PROP_FPS)
            self.video_frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.video_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            self.video_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            if self.video_fps <= 0 or self.video_frame_count <= 0:
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±ç‰‡è³‡è¨Š")
                print(f"FPS: {self.video_fps}")
                print(f"ç¸½å¹€æ•¸: {self.video_frame_count}")
                return False
            
            print(f"ğŸ“¹ å½±ç‰‡è³‡è¨Š:")
            print(f"è§£æåº¦: {self.video_width}x{self.video_height}")
            print(f"å¹€ç‡: {self.video_fps} FPS")
            print(f"ç¸½å¹€æ•¸: {self.video_frame_count}")
            print(f"æª”æ¡ˆå¤§å°: {os.path.getsize(video_path) / (1024*1024):.2f} MB")
            
            # æ¸¬è©¦è®€å–ç¬¬ä¸€å¹€
            ret, frame = self.cap.read()
            if not ret or frame is None:
                print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±ç‰‡å¹€")
                return False
                
            # é‡ç½®å½±ç‰‡ä½ç½®
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def add_axis_position(self, shoulder, elbow, wrist, timestamp):
        """æ·»åŠ æ‰‹è»¸ä½ç½®"""
        if len(self.positions) > 0:
            prev_shoulder, prev_elbow, prev_wrist = self.positions[-1]
            
            # è¨ˆç®—æ‰‹æŒé€Ÿåº¦
            dx_wrist = abs(wrist[0] - prev_wrist[0])
            dy_wrist = abs(wrist[1] - prev_wrist[1])
            distance_wrist = math.sqrt(dx_wrist**2 + dy_wrist**2)
            
            # è¨ˆç®—æ‰‹è‚˜é€Ÿåº¦
            dx_elbow = abs(elbow[0] - prev_elbow[0])
            dy_elbow = abs(elbow[1] - prev_elbow[1])
            distance_elbow = math.sqrt(dx_elbow**2 + dy_elbow**2)
            
            time_diff = timestamp - self.time_history[-1]
            if time_diff > 0:
                # è¨ˆç®—æ‰‹æŒé€Ÿåº¦
                distance_wrist_m = distance_wrist / self.pixels_per_meter
                wrist_speed = distance_wrist_m / time_diff
                self.wrist_speed_history.append(wrist_speed)
                
                # è¨ˆç®—æ‰‹è‚˜é€Ÿåº¦
                distance_elbow_m = distance_elbow / self.pixels_per_meter
                elbow_speed = distance_elbow_m / time_diff
                self.elbow_speed_history.append(elbow_speed)
            else:
                self.wrist_speed_history.append(0)
                self.elbow_speed_history.append(0)
        else:
            self.wrist_speed_history.append(0)
            self.elbow_speed_history.append(0)

        # è¨ˆç®—è§’åº¦
        angle = self.calculate_angle(shoulder, elbow, wrist)
        self.angles.append(angle)
        
        self.positions.append((shoulder, elbow, wrist))
        self.time_history.append(timestamp)

    def calculate_angle(self, shoulder, elbow, wrist):
        """è¨ˆç®—æ‰‹è»¸è§’åº¦"""
        # è¨ˆç®—å‘é‡
        v1 = (elbow[0] - shoulder[0], elbow[1] - shoulder[1])
        v2 = (wrist[0] - elbow[0], wrist[1] - elbow[1])
        
        # è¨ˆç®—è§’åº¦
        dot_product = v1[0] * v2[0] + v1[1] * v2[1]
        v1_mag = math.sqrt(v1[0]**2 + v1[1]**2)
        v2_mag = math.sqrt(v2[0]**2 + v2[1]**2)
        
        if v1_mag * v2_mag == 0:
            return 0
            
        cos_angle = dot_product / (v1_mag * v2_mag)
        cos_angle = max(-1, min(1, cos_angle))  # ç¢ºä¿åœ¨ [-1, 1] ç¯„åœå…§
        angle = math.degrees(math.acos(cos_angle))
        
        return angle

    def draw_trajectory(self, image):
        """ç¹ªè£½è»Œè·¡ï¼ˆåªä¿ç•™æ‰‹æŒï¼‰"""
        if len(self.positions) < 2:
            return image
        # åªç¹ªè£½æ‰‹æŒï¼ˆwristï¼‰è»Œè·¡ç·š
        for i in range(1, len(self.positions)):
            prev_shoulder, prev_elbow, prev_wrist = self.positions[i-1]
            curr_shoulder, curr_elbow, curr_wrist = self.positions[i]
            alpha = i / len(self.positions)
            color = (0, int(255 * (1-alpha)), int(255 * alpha))
            cv2.line(image, prev_wrist, curr_wrist, color, 2)
        return image

    def draw_statistics(self, image):
        """ç¹ªè£½çµ±è¨ˆè³‡è¨Š (å·²ç§»é™¤å³æ™‚é¡¯ç¤ºåŠŸèƒ½)"""
        return image  # ä¿ç•™ç©ºæ–¹æ³•ä»¥é˜²æ­¢å…¶ä»–åœ°æ–¹èª¿ç”¨å‡ºéŒ¯

    def process_video_frame(self, frame):
        """è™•ç†å½±ç‰‡å¹€ (åƒ…ä¿ç•™è»Œè·¡æç¹ªåŠŸèƒ½)"""
        if frame is None:
            return None

        try:
            # è½‰æ›é¡è‰²ç©ºé–“
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.pose.process(image)
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # ç¹ªè£½éª¨æ¶
            if results.pose_landmarks:
                self.mp_drawing.draw_landmarks(
                    image,
                    results.pose_landmarks,
                    self.mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
                )

                # ç²å–é—œéµé»
                landmarks = results.pose_landmarks.landmark
                shoulder = (int(landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * self.video_width),
                           int(landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * self.video_height))
                elbow = (int(landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value].x * self.video_width),
                        int(landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value].y * self.video_height))
                wrist = (int(landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value].x * self.video_width),
                        int(landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value].y * self.video_height))

                # æ·»åŠ ä½ç½®å’Œè¨ˆç®—é€Ÿåº¦
                current_time = self.current_frame / self.video_fps
                self.add_axis_position(shoulder, elbow, wrist, current_time)

                # ç¹ªè£½è»Œè·¡
                image = self.draw_trajectory(image)

            return image

        except Exception as e:
            print(f"âŒ è™•ç†å½±ç‰‡å¹€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return frame

    def start_recording(self):
        """é–‹å§‹è¨˜éŒ„"""
        self.recording = True
        self.record_start_time = time.time()
        print("ğŸ¥ é–‹å§‹è¨˜éŒ„")

    def stop_recording(self):
        """åœæ­¢è¨˜éŒ„"""
        self.recording = False
        print("â¹ åœæ­¢è¨˜éŒ„")

    def export_analysis_report(self):
        """Export analysis report"""
        if not self.wrist_speed_history or not self.elbow_speed_history or not self.time_history:
            print("âŒ No data to export")
            return

        # Create output directory
        output_dir = 'analysis_reports'
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # Generate filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_filename = f'analysis_report_{timestamp}'

        # Calculate statistics
        max_wrist_speed = max(self.wrist_speed_history)
        max_elbow_speed = max(self.elbow_speed_history)
        avg_wrist_speed = sum(self.wrist_speed_history)/len(self.wrist_speed_history)
        avg_elbow_speed = sum(self.elbow_speed_history)/len(self.elbow_speed_history)
        max_angle = max(self.angles) if self.angles else 0
        min_angle = min(self.angles) if self.angles else 0

        # Speed-time chart
        plt.figure(figsize=(12, 6))
        plt.plot(self.time_history, self.wrist_speed_history, 'g-', label='Wrist Speed')
        plt.plot(self.time_history, self.elbow_speed_history, 'r-', label='Elbow Speed')
        plt.title(f'Arm Movement Speed Analysis\n'
                 f'Max Wrist Speed: {max_wrist_speed:.2f} m/s | Max Elbow Speed: {max_elbow_speed:.2f} m/s\n'
                 f'Video Info: {self.video_width}x{self.video_height} @ {self.video_fps}fps',
                 fontsize=12, pad=20)
        plt.xlabel('Time (s)', fontsize=10)
        plt.ylabel('Speed (m/s)', fontsize=10)
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.legend(fontsize=10)
        plt.text(0.02, 0.98, 
                f'Max Wrist Speed: {max_wrist_speed:.2f} m/s\n'
                f'Avg Wrist Speed: {avg_wrist_speed:.2f} m/s\n'
                f'Max Elbow Speed: {max_elbow_speed:.2f} m/s\n'
                f'Avg Elbow Speed: {avg_elbow_speed:.2f} m/s',
                transform=plt.gca().transAxes,
                verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'{base_filename}_speed.png'), dpi=300, bbox_inches='tight')
        plt.close()

        # åŠ é€Ÿåº¦åœ–è¡¨
        wrist_acceleration = [0]
        for i in range(1, len(self.wrist_speed_history)):
            dt = self.time_history[i] - self.time_history[i-1]
            if dt > 1e-6:
                acc = (self.wrist_speed_history[i] - self.wrist_speed_history[i-1]) / dt
            else:
                acc = 0
            wrist_acceleration.append(acc)
        plt.figure(figsize=(12, 6))
        plt.plot(self.time_history, wrist_acceleration, 'b-', label='Wrist Acceleration')
        plt.title(f'Wrist Acceleration Analysis\n'
                 f'Video Info: {self.video_width}x{self.video_height} @ {self.video_fps}fps',
                 fontsize=12, pad=20)
        plt.xlabel('Time (s)', fontsize=10)
        plt.ylabel('Acceleration (m/sÂ²)', fontsize=10)
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.legend(fontsize=10)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'{base_filename}_acceleration.png'), dpi=300, bbox_inches='tight')
        plt.close()

        # Generate text report
        report_path = os.path.join(output_dir, f'{base_filename}_report.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("Arm Movement Analysis Report\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Video Information:\n")
            f.write(f"Resolution: {self.video_width}x{self.video_height}\n")
            f.write(f"Frame Rate: {self.video_fps} FPS\n")
            f.write(f"Total Frames: {self.video_frame_count}\n")
            f.write(f"File Size: {os.path.getsize(self.video_path) / (1024*1024):.2f} MB\n\n")
            f.write("Movement Data:\n")
            f.write(f"Max Wrist Speed: {max_wrist_speed:.2f} m/s\n")
            f.write(f"Avg Wrist Speed: {avg_wrist_speed:.2f} m/s\n")
            f.write(f"Max Elbow Speed: {max_elbow_speed:.2f} m/s\n")
            f.write(f"Avg Elbow Speed: {avg_elbow_speed:.2f} m/s\n")
            if self.angles:
                f.write(f"Max Angle: {max_angle:.1f} degrees\n")
                f.write(f"Min Angle: {min_angle:.1f} degrees\n")
            f.write("\nTime Point Analysis:\n")
            for i, (t, ws, es, acc) in enumerate(zip(self.time_history, self.wrist_speed_history, self.elbow_speed_history, wrist_acceleration)):
                f.write(f"Time {t:.2f}s: Wrist Speed {ws:.2f} m/s, Elbow Speed {es:.2f} m/s, Wrist Acc {acc:.2f} m/sÂ²")
                if self.angles:
                    f.write(f", Angle {self.angles[i]:.1f} degrees")
                f.write("\n")
        print(f"âœ… Analysis report saved to: {output_dir}")
        print(f"ğŸ“Š Generated charts:")
        print(f"   - {base_filename}_speed.png")
        print(f"   - {base_filename}_acceleration.png")
        print(f"ğŸ“ Generated report: {base_filename}_report.txt")

    def release_resources(self):
        """é‡‹æ”¾è³‡æº"""
        if self.cap is not None:
            self.cap.release()
            print("âœ… ArmAxisTracker è³‡æºå·²é‡‹æ”¾")

def main():
    """ä¸»å‡½æ•¸ - æ‰‹è»¸è¿½è¹¤"""
    print("\n" + "=" * 50)
    print("ğŸš€ æ‰‹è»¸è¿½è¹¤ç³»çµ±å•Ÿå‹•")
    print("=" * 50)
    
    # é¡¯ç¤ºç³»çµ±è³‡è¨Š
    print("\nğŸ“‹ ç³»çµ±è³‡è¨Š:")
    print(f"ä½œæ¥­ç³»çµ±: {os.name}")
    print(f"å·¥ä½œç›®éŒ„: {os.getcwd()}")
    print(f"Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    
    try:
        print(f"\nğŸ“‹ å¥—ä»¶ç‰ˆæœ¬:")
        print(f"OpenCV ç‰ˆæœ¬: {cv2.__version__}")
        print(f"MediaPipe ç‰ˆæœ¬: {mp.__version__}")
        print(f"NumPy ç‰ˆæœ¬: {np.__version__}")
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–ç‰ˆæœ¬ä¿¡æ¯: {e}")

    # æª¢æŸ¥å¿…è¦çš„ç›®éŒ„
    print("\nğŸ“‚ ç›®éŒ„æª¢æŸ¥:")
    if not os.path.exists('analysis_reports'):
        try:
            os.makedirs('analysis_reports')
            print("âœ… å·²å‰µå»º analysis_reports ç›®éŒ„")
        except Exception as e:
            print(f"âŒ ç„¡æ³•å‰µå»º analysis_reports ç›®éŒ„: {e}")
    else:
        print("âœ… analysis_reports ç›®éŒ„å·²å­˜åœ¨")

    arm_tracker = ArmAxisTracker()
    
    # è™•ç†å½±ç‰‡è·¯å¾‘è¼¸å…¥
    print("\nğŸ“¹ è«‹è¼¸å…¥å½±ç‰‡è·¯å¾‘")
    print("æç¤ºï¼š")
    print("1. å¯ä»¥ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ˆä¾‹å¦‚ï¼švideos/test.mp4ï¼‰")
    print("2. æˆ–ä½¿ç”¨çµ•å°è·¯å¾‘ï¼ˆä¾‹å¦‚ï¼šC:/Users/YourName/Videos/test.mp4ï¼‰")
    print("3. æ”¯æ´çš„æ ¼å¼ï¼šMP4, AVI, MOV ç­‰")
    print("4. æŒ‰ Ctrl+C å¯ä»¥éš¨æ™‚é€€å‡ºç¨‹å¼")
    print("-" * 50)
    
    while True:
        try:
            video_path = input("\nè«‹è¼¸å…¥å½±ç‰‡è·¯å¾‘: ").strip()
            if not video_path:
                print("âŒ éŒ¯èª¤ï¼šè·¯å¾‘ä¸èƒ½ç‚ºç©º")
                continue
                
            # ç§»é™¤å¼•è™Ÿï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            video_path = video_path.strip('"\'')
            
            if arm_tracker.load_video(video_path):
                break
            else:
                print("\nè«‹é‡æ–°è¼¸å…¥å½±ç‰‡è·¯å¾‘ï¼Œæˆ–æŒ‰ Ctrl+C é€€å‡ºç¨‹å¼")
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼å·²çµ‚æ­¢")
            return
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("è«‹é‡æ–°è¼¸å…¥å½±ç‰‡è·¯å¾‘")

    print("\nğŸ¬ é–‹å§‹åˆ†æå½±ç‰‡...")
    print("ğŸ“ æ§åˆ¶èªªæ˜:")
    print("p: æš«åœ/æ¢å¾©")
    print("r: é‡ç½®")
    print("s: é–‹å§‹/åœæ­¢è¨˜éŒ„")
    print("e: åŒ¯å‡ºåˆ†æå ±å‘Š")
    print("[: æ¸›æ…¢æ’­æ”¾é€Ÿåº¦")
    print("]: åŠ å¿«æ’­æ”¾é€Ÿåº¦")
    print("ESC: é€€å‡º")
    print("-" * 50)

    try:
        print("\nğŸ¤– æ­£åœ¨åˆå§‹åŒ– MediaPipe Pose...")
        print("âœ… MediaPipe Pose åˆå§‹åŒ–æˆåŠŸ")
        
        paused = False
        recording = False
        analysis_complete = False

        while True:
            if not paused:
                ret, frame = arm_tracker.cap.read()
                if not ret:
                    print("\nâœ… å½±ç‰‡æ’­æ”¾å®Œæˆ")
                    analysis_complete = True
                    break

                processed_frame = arm_tracker.process_video_frame(frame)
                if processed_frame is not None:
                    cv2.imshow('Arm Axis Tracker', processed_frame)
                    arm_tracker.current_frame += 1

            wait_time = max(1, int(1000/arm_tracker.video_fps/arm_tracker.playback_speed))
            key = cv2.waitKey(wait_time) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('r'):  # Reset
                arm_tracker.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                arm_tracker.current_frame = 0
            elif key == ord('p'):  # Pause/Resume
                paused = not paused
                print("â¸ æš«åœ" if paused else "â–¶ï¸ æ¢å¾©")
            elif key == ord('s'):  # Start/Stop Recording
                if not arm_tracker.recording:
                    arm_tracker.start_recording()
                else:
                    arm_tracker.stop_recording()
            elif key == ord('e'):  # Export Report
                arm_tracker.export_analysis_report()
            elif key == ord('['):  # Slow down
                arm_tracker.playback_speed = max(0.25, arm_tracker.playback_speed - 0.25)
                print(f"æ’­æ”¾é€Ÿåº¦: {arm_tracker.playback_speed}x")
            elif key == ord(']'):  # Speed up
                arm_tracker.playback_speed = min(2.0, arm_tracker.playback_speed + 0.25)
                print(f"æ’­æ”¾é€Ÿåº¦: {arm_tracker.playback_speed}x")

        # å½±ç‰‡æ’­æ”¾å®Œæˆå¾Œï¼Œè©¢å•æ˜¯å¦è¦åŒ¯å‡ºå ±å‘Š
        if analysis_complete:
            print("\nğŸ“Š åˆ†æå®Œæˆï¼")
            export = input("æ˜¯å¦è¦åŒ¯å‡ºåˆ†æå ±å‘Šï¼Ÿ(y/n): ").lower()
            if export == 'y':
                arm_tracker.export_analysis_report()
                print("âœ… å ±å‘Šå·²åŒ¯å‡º")

    except Exception as e:
        print(f"\nâŒ ä¸»ç¨‹å¼å´©æ½°: {e}")
        import traceback
        traceback.print_exc()
    finally:
        arm_tracker.release_resources()
        cv2.destroyAllWindows()
        print("\nğŸ§¹ è³‡æºå·²é‡‹æ”¾")
        print("ğŸ‘‹ ç¨‹å¼çµæŸ")

if __name__ == "__main__":
    main()