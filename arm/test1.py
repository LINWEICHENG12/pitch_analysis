import cv2
import mediapipe as mp
import time
import math
from collections import deque
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os

class ArmAxisTracker:
    def __init__(self, max_history=300, pixels_per_meter=300):
        self.max_history = max_history
        self.pixels_per_meter = pixels_per_meter
        self.axis_trajectory = deque(maxlen=max_history)
        self.timestamps = deque(maxlen=max_history)
        self.total_displacement = 0.0
        self.max_speed = 0.0
        self.speeds = deque(maxlen=50)
        self.angles = deque(maxlen=max_history)
        self.frame_queue = queue.Queue(maxsize=30)
        self.result_queue = queue.Queue(maxsize=30)
        self.running = True
        self.fps = 0
        self.frame_count = 0
        self.start_time = time.time()
        self.speed_history = []
        self.time_history = []
        self.recording = False
        self.record_start_time = 0

    def add_axis_position(self, shoulder, elbow, wrist, timestamp):
        """æ·»åŠ è‚©è†€ã€æ‰‹è‚˜å’Œæ‰‹è…•ä½ç½®ï¼Œè¨ˆç®—é€Ÿåº¦å’Œè§’åº¦"""
        if not shoulder or not elbow or not wrist:
            return

        # è¨ˆç®—æ‰‹è‚˜ä½ç½®
        self.axis_trajectory.append(elbow)
        self.timestamps.append(timestamp)

        # è¨ˆç®—è§’åº¦
        angle = self._calculate_angle(shoulder, elbow, wrist)
        self.angles.append(angle)

        # è¨ˆç®—é€Ÿåº¦
        if len(self.timestamps) >= 2:
            self._calculate_speed()
            
            # å¦‚æœæ­£åœ¨è¨˜éŒ„ï¼Œä¿å­˜é€Ÿåº¦å’Œæ™‚é–“
            if self.recording:
                self.speed_history.append(self.speeds[-1])
                self.time_history.append(timestamp - self.record_start_time)

    def _calculate_angle(self, shoulder, elbow, wrist):
        """è¨ˆç®—è‚©è†€ã€æ‰‹è‚˜å’Œæ‰‹è…•çš„å¤¾è§’"""
        # å‘é‡1ï¼šè‚©è†€ -> æ‰‹è‚˜
        v1 = (shoulder[0] - elbow[0], shoulder[1] - elbow[1])
        # å‘é‡2ï¼šæ‰‹è…• -> æ‰‹è‚˜
        v2 = (wrist[0] - elbow[0], wrist[1] - elbow[1])

        # è¨ˆç®—å‘é‡çš„å…§ç©å’Œæ¨¡é•·
        dot_product = v1[0] * v2[0] + v1[1] * v2[1]
        magnitude_v1 = math.sqrt(v1[0]**2 + v1[1]**2)
        magnitude_v2 = math.sqrt(v2[0]**2 + v2[1]**2)

        if magnitude_v1 == 0 or magnitude_v2 == 0:
            return 0.0

        # è¨ˆç®—è§’åº¦ï¼ˆå¼§åº¦è½‰è§’åº¦ï¼‰
        angle = math.acos(dot_product / (magnitude_v1 * magnitude_v2))
        return math.degrees(angle)

    def _calculate_speed(self):
        """è¨ˆç®—æ‰‹è‚˜é€Ÿåº¦"""
        curr = self.axis_trajectory[-1]
        prev = self.axis_trajectory[-2]
        dx = curr[0] - prev[0]
        dy = curr[1] - prev[1]
        dist_px = math.sqrt(dx**2 + dy**2)

        dt = self.timestamps[-1] - self.timestamps[-2]
        if dt <= 0:
            return

        # è¨ˆç®—é€Ÿåº¦ (å°‡æ™‚é–“å¾æ¯«ç§’è½‰æ›ç‚ºç§’)
        dist_m = dist_px / self.pixels_per_meter
        speed = (dist_m / dt) * 1000  # å°‡æ¯«ç§’è½‰æ›ç‚ºç§’
        self.speeds.append(speed)

        # æ›´æ–°æœ€å¤§é€Ÿåº¦
        if speed > self.max_speed:
            self.max_speed = speed

    def draw_trajectory(self, image):
        """åœ¨å½±åƒä¸Šç¹ªè£½æ‰‹è»¸è»Œè·¡ï¼ˆé€£çºŒç·šæ¢ï¼‰"""
        if len(self.axis_trajectory) < 2:
            return image

        # ä½¿ç”¨ numpy é€²è¡Œå‘é‡åŒ–é‹ç®—
        points = np.array(self.axis_trajectory, dtype=np.int32)
        cv2.polylines(image, [points], False, (0, 255, 0), 2)
        return image

    def draw_statistics(self, image):
        """åœ¨å½±åƒä¸Šé¡¯ç¤ºçµ±è¨ˆæ•¸æ“š"""
        # è¨ˆç®— FPS
        self.frame_count += 1
        elapsed_time = time.time() - self.start_time
        if elapsed_time > 0:
            self.fps = self.frame_count / elapsed_time

        cv2.putText(image, f"FPS: {self.fps:.1f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(image, f"Max Speed: {self.max_speed:.2f} m/s",
                    (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(image, f"Total Distance: {self.total_displacement:.2f} m",
                    (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        if self.angles:
            cv2.putText(image, f"Current Angle: {self.angles[-1]:.2f} degrees",
                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        return image

    def start_recording(self):
        """é–‹å§‹è¨˜éŒ„é€Ÿåº¦æ•¸æ“š"""
        self.recording = True
        self.speed_history = []
        self.time_history = []
        self.record_start_time = time.time()
        print("ğŸ“ é–‹å§‹è¨˜éŒ„é€Ÿåº¦æ•¸æ“š")

    def stop_recording(self):
        """åœæ­¢è¨˜éŒ„é€Ÿåº¦æ•¸æ“š"""
        self.recording = False
        print("â¹ åœæ­¢è¨˜éŒ„é€Ÿåº¦æ•¸æ“š")

    def export_speed_graph(self):
        """åŒ¯å‡ºé€Ÿåº¦-æ™‚é–“åœ–è¡¨"""
        if not self.speed_history or not self.time_history:
            print("âŒ æ²’æœ‰å¯åŒ¯å‡ºçš„æ•¸æ“š")
            return

        # å‰µå»ºåœ–è¡¨
        plt.figure(figsize=(10, 6))
        plt.plot(self.time_history, self.speed_history, 'b-', label='æ‰‹è»¸ç§»å‹•é€Ÿåº¦')
        plt.title('æ‰‹è»¸ç§»å‹•é€Ÿåº¦éš¨æ™‚é–“è®ŠåŒ–')
        plt.xlabel('æ™‚é–“ (ç§’)')
        plt.ylabel('é€Ÿåº¦ (m/s)')
        plt.grid(True)
        plt.legend()

        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = 'speed_graphs'
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆä½¿ç”¨æ™‚é–“æˆ³ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'speed_graph_{timestamp}.png'
        filepath = os.path.join(output_dir, filename)

        # ä¿å­˜åœ–è¡¨
        plt.savefig(filepath)
        plt.close()
        print(f"âœ… åœ–è¡¨å·²ä¿å­˜è‡³: {filepath}")

    def process_frame(self, frame, pose):
        """è™•ç†å–®ä¸€å¹€å½±åƒ"""
        if frame is None:
            return None

        current_time = time.time()
        frame = cv2.flip(frame, 1)

        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False
        results = pose.process(image_rgb)
        image_rgb.flags.writeable = True
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)

        if results.pose_landmarks:
            mp_drawing = mp.solutions.drawing_utils
            mp_pose = mp.solutions.pose
            mp_drawing.draw_landmarks(
                image_bgr,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=2)
            )

            h, w, _ = image_bgr.shape
            lm = results.pose_landmarks.landmark
            shoulder = (
                int(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w),
                int(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h)
            )
            elbow = (
                int(lm[mp_pose.PoseLandmark.RIGHT_ELBOW].x * w),
                int(lm[mp_pose.PoseLandmark.RIGHT_ELBOW].y * h)
            )
            wrist = (
                int(lm[mp_pose.PoseLandmark.RIGHT_WRIST].x * w),
                int(lm[mp_pose.PoseLandmark.RIGHT_WRIST].y * h)
            )

            self.add_axis_position(shoulder, elbow, wrist, current_time)
            image_bgr = self.draw_trajectory(image_bgr)
            image_bgr = self.draw_statistics(image_bgr)

        return image_bgr

def main():
    """ä¸»å‡½æ•¸ - æ‰‹è»¸è¿½è¹¤"""
    print("ğŸš€ æ‰‹è»¸è¿½è¹¤ç³»çµ±å•Ÿå‹•")
    print("=" * 50)
    
    try:
        print(f"ğŸ“‹ OpenCV ç‰ˆæœ¬: {cv2.__version__}")
        print(f"ğŸ§  MediaPipe ç‰ˆæœ¬: {mp.__version__}")
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–ç‰ˆæœ¬ä¿¡æ¯: {e}")

    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils

    arm_tracker = ArmAxisTracker()

    print("ğŸ¥ æ­£åœ¨åˆå§‹åŒ–æ”å½±æ©Ÿ...")
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
        print("å»ºè­°æª¢æŸ¥:")
        print("1. æ”å½±æ©Ÿæ˜¯å¦è¢«å…¶ä»–ç¨‹å¼ä½¿ç”¨")
        print("2. æ”å½±æ©Ÿé©…å‹•ç¨‹å¼æ˜¯å¦æ­£å¸¸")
        print("3. Windows éš±ç§è¨­å®šæ˜¯å¦å…è¨±æ”å½±æ©Ÿå­˜å–")
        return
    
    print("âœ… æ”å½±æ©Ÿåˆå§‹åŒ–æˆåŠŸ")
    
    # è¨­ç½®æ”å½±æ©Ÿåƒæ•¸
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)

    try:
        print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ– MediaPipe Pose...")
        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:
            print("âœ… MediaPipe Pose åˆå§‹åŒ–æˆåŠŸ")
            print("ğŸ“ æ§åˆ¶èªªæ˜:")
            print("p: æš«åœ/æ¢å¾©")
            print("r: é‡ç½®")
            print("s: é–‹å§‹/åœæ­¢è¨˜éŒ„")
            print("e: åŒ¯å‡ºåœ–è¡¨")
            print("ESC: é€€å‡º")
            
            paused = False
            recording = False

            def capture_frames():
                print("ğŸ“¸ é–‹å§‹æ“·å–å½±åƒ...")
                frame_count = 0
                while arm_tracker.running:
                    if not paused:
                        ret, frame = cap.read()
                        if ret:
                            arm_tracker.frame_queue.put(frame)
                            frame_count += 1
                            if frame_count % 30 == 0:  # æ¯30å¹€é¡¯ç¤ºä¸€æ¬¡ç‹€æ…‹
                                print(f"ğŸ“Š å·²æ“·å– {frame_count} å¹€å½±åƒ")
                        else:
                            print("âŒ ç„¡æ³•è®€å–å½±åƒï¼Œè·³å‡ºè¿´åœˆ")
                            break
                    time.sleep(0.001)
                print("ğŸ“¸ åœæ­¢æ“·å–å½±åƒ")

            def process_frames():
                print("ğŸ”„ é–‹å§‹è™•ç†å½±åƒ...")
                frame_count = 0
                while arm_tracker.running:
                    if not paused and not arm_tracker.frame_queue.empty():
                        try:
                            frame = arm_tracker.frame_queue.get(timeout=1.0)
                            processed_frame = arm_tracker.process_frame(frame, pose)
                            if processed_frame is not None:
                                arm_tracker.result_queue.put(processed_frame)
                                frame_count += 1
                                if frame_count % 30 == 0:  # æ¯30å¹€é¡¯ç¤ºä¸€æ¬¡ç‹€æ…‹
                                    print(f"ğŸ”„ å·²è™•ç† {frame_count} å¹€å½±åƒ")
                        except queue.Empty:
                            print("âš ï¸ ç­‰å¾…å½±åƒä¸­...")
                            continue
                    time.sleep(0.001)
                print("ğŸ”„ åœæ­¢è™•ç†å½±åƒ")

            # å‰µå»ºåŸ·è¡Œç·’æ± 
            print("ğŸ§µ å•Ÿå‹•åŸ·è¡Œç·’...")
            with ThreadPoolExecutor(max_workers=2) as executor:
                # å•Ÿå‹•åŸ·è¡Œç·’
                capture_thread = executor.submit(capture_frames)
                process_thread = executor.submit(process_frames)

                print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼Œé–‹å§‹è¿½è¹¤...")
                while True:
                    if not arm_tracker.result_queue.empty():
                        try:
                            frame = arm_tracker.result_queue.get(timeout=1.0)
                            cv2.putText(frame, "p:Pause/Resume  r:Reset  s:Record  e:Export  ESC:Exit",
                                        (10, frame.shape[0] - 20),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                            cv2.imshow('Arm Axis Tracker', frame)
                        except queue.Empty:
                            print("âš ï¸ ç­‰å¾…è™•ç†çµæœä¸­...")
                            continue

                    key = cv2.waitKey(1) & 0xFF
                    if key == 27:  # ESC
                        print("ğŸ‘‹ ä½¿ç”¨è€…è¦æ±‚é€€å‡º")
                        break
                    elif key == ord('r'):  # Reset
                        arm_tracker = ArmAxisTracker()
                        print("ğŸ”„ è»Œè·¡å·²é‡ç½®")
                    elif key == ord('p'):  # Pause/Resume
                        paused = not paused
                        print("â¸ æš«åœ" if paused else "â–¶ï¸ æ¢å¾©")
                    elif key == ord('s'):  # Start/Stop Recording
                        if not arm_tracker.recording:
                            arm_tracker.start_recording()
                        else:
                            arm_tracker.stop_recording()
                    elif key == ord('e'):  # Export Graph
                        arm_tracker.export_speed_graph()

                # åœæ­¢åŸ·è¡Œç·’
                print("ğŸ›‘ æ­£åœ¨åœæ­¢åŸ·è¡Œç·’...")
                arm_tracker.running = False
                capture_thread.result()
                process_thread.result()
                print("âœ… åŸ·è¡Œç·’å·²åœæ­¢")

    except Exception as e:
        print(f"âŒ ä¸»ç¨‹å¼å´©æ½°: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("ğŸ§¹ æ­£åœ¨é‡‹æ”¾è³‡æº...")
        cap.release()
        cv2.destroyAllWindows()
        print("âœ… è³‡æºå·²é‡‹æ”¾")

if __name__ == "__main__":
    main()